{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# from hw2_corpus_tool import *\n",
    "# import pycrfsuite\n",
    "# import random\n",
    "# import shutil\n",
    "\n",
    "# train_data_path = './train/train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data = set(os.listdir(train_data_path))\n",
    "# test_sample = random.sample(train_data, int(len(train_data)*0.25))\n",
    "# dev_sample = train_data-set(test_sample)\n",
    "\n",
    "# for file_name in dev_sample:\n",
    "#     path = os.path.join(train_data_path, file_name)\n",
    "#     shutil.copy(path, './dev')\n",
    "    \n",
    "# for file_name in test_sample:\n",
    "#     path = os.path.join(train_data_path, file_name)\n",
    "#     shutil.copy(path, './test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from hw2_corpus_tool import *\n",
    "import pycrfsuite\n",
    "import random\n",
    "\n",
    "train_path = './dev'\n",
    "test_path = './test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(utterance, first_utterance, last_speaker):\n",
    "    features = []\n",
    "    if(last_speaker and utterance.speaker != last_speaker):\n",
    "        features.append('SPEAKER_CHANGE')\n",
    "        \n",
    "    if(first_utterance):\n",
    "        features.append('FIRST_UTTERANCE')\n",
    "    \n",
    "    if(not utterance.pos):\n",
    "        return features, utterance.speaker, utterance.act_tag\n",
    "    \n",
    "    for token, pos in utterance.pos:\n",
    "        features.append('TOKEN_'+token)\n",
    "        features.append('POS_'+pos)\n",
    "    \n",
    "    return features, utterance.speaker, utterance.act_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(path, advanced=False):\n",
    "    dataset = get_data(path)\n",
    "    x_final = []\n",
    "    y_final = []\n",
    "    for conversation in dataset:\n",
    "        x = []\n",
    "        y = []\n",
    "        first_utterance = True\n",
    "        last_speaker = None\n",
    "        for utterance in conversation:\n",
    "            if(advanced):\n",
    "                features, last_speaker, label = get_advanced_features(utterance, first_utterance, last_speaker)\n",
    "            else:\n",
    "                features, last_speaker, label = get_features(utterance, first_utterance, last_speaker)\n",
    "            x.append(features)\n",
    "            y.append(label)\n",
    "            if(first_utterance):\n",
    "                first_utterance = False\n",
    "        x_final.append(x)\n",
    "        y_final.append(y)\n",
    "    return x_final, y_final\n",
    "\n",
    "# x_train, y_train = create_dataset(train_path)\n",
    "# x_test, y_test = create_dataset(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(x_train, y_train):\n",
    "    trainer = pycrfsuite.Trainer(verbose=False)\n",
    "\n",
    "    for (x, y) in zip(x_train, y_train):\n",
    "        trainer.append(x, y)\n",
    "\n",
    "    trainer.set_params({\n",
    "        'c1': 1.0, # coefficient for L1 penalty\n",
    "        'c2': 1e-3, # coefficient for L2 penalty\n",
    "        'max_iterations': 50, # stop earlier\n",
    "        # include transitions that are possible, but not observed\n",
    "        'feature.possible_transitions': True\n",
    "    })\n",
    "\n",
    "    trainer.train('baseline_tagger.crfsuite')\n",
    "    return \n",
    "\n",
    "train(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(x_test):\n",
    "    y_pred = []\n",
    "    crftagger = pycrfsuite.Tagger()\n",
    "    crftagger.open('baseline_tagger.crfsuite')\n",
    "\n",
    "    for x in x_test:\n",
    "        y_pred.append(crftagger.tag(x))\n",
    "\n",
    "    return y_pred\n",
    "\n",
    "y_pred = predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7274062620796289"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def calculate_accuracy(y_pred, y_test):\n",
    "    correct = 0\n",
    "    for c_pred, c_test in zip(y_pred, y_test):\n",
    "        for l1, l2 in zip(c_pred, c_test):\n",
    "            if(l1 == l2):\n",
    "                correct += 1\n",
    "    return correct/sum([len(x) for x in y_test])   \n",
    "\n",
    "calculate_accuracy(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_advanced_features(utterance, first_utterance, last_speaker):\n",
    "    features = []\n",
    "    if(last_speaker and utterance.speaker != last_speaker):\n",
    "        features.append('SPEAKER_CHANGE')\n",
    "        \n",
    "    if(first_utterance):\n",
    "        features.append('FIRST_UTTERANCE')\n",
    "    \n",
    "    if(not utterance.pos):\n",
    "        features.append('NO_WORD')\n",
    "        return features, utterance.speaker, utterance.act_tag\n",
    "    \n",
    "    for i, (token, pos) in enumerate(utterance.pos):\n",
    "        if(i == 0):\n",
    "            features.append('SOS_TOKEN_'+token)\n",
    "            features.append('SOS_POS_'+pos)\n",
    "        if(i == len(utterance.pos)-1):\n",
    "            features.append('EOS_TOKEN_'+token)\n",
    "            features.append('EOS_POS_'+pos)\n",
    "        \n",
    "        features.append('TOKEN_'+token)\n",
    "        features.append('POS_'+pos)\n",
    "        \n",
    "    for pos1, pos2 in zip(utterance.pos[:-1], utterance.pos[1:]):\n",
    "        features.append(\"BIGRAM_{}_{}\".format(pos1.token, pos2.token))\n",
    "        features.append(\"BIGRAM_POS_{}_{}\".format(pos1.pos, pos2.pos))\n",
    "    \n",
    "    return features, utterance.speaker, utterance.act_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7541553923463471\n",
      "330.89393973350525\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "st = time.time()\n",
    "x_train, y_train = create_dataset(train_path, advanced=True)\n",
    "x_test, y_test = create_dataset(test_path, advanced=True)\n",
    "train(x_train, y_train)\n",
    "y_pred = predict(x_test)\n",
    "print(calculate_accuracy(y_pred, y_test))\n",
    "print(time.time()-st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "element = next(get_data(train_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = element[0].pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosTag(token='are', pos='VBP'),\n",
       " PosTag(token='your', pos='PRP$'),\n",
       " PosTag(token='favorite', pos='JJ'),\n",
       " PosTag(token='programs', pos='NNS'),\n",
       " PosTag(token='?', pos='.')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigrams = [\"{}_{}\".format(x.token, y.token) for (x, y) in zip(sent[:-1], sent[1:])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['What-are', 'are-your', 'your-favorite', 'favorite-programs', 'programs-?']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
